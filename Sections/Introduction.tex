% !TEX root =  ../unref_general.tex
\section{Introduction}
\label{sec:intro}
The Finite Element Method (FEM) is commonly employed to approximate solutions of Partial Differential Equations (PDEs) that govern multiple physical phenomena. This numerical technique allows to handle complex geometries (\revbdos{see, e.g.,}~\cite{larsson2008partial,johnson2012numerical} among others) and model a wide variety of physical problems and engineering applications. However, the computational cost required to obtain accurate finite element solutions often becomes prohibitive, and it is then necessary to develop specific strategies to minimize the solution cost.

The design of \reva{efficient} meshes is one of the available tools to minimize computational costs. There exist multiple adaptive FEMs to perform this task. For example, $h$-adaptive FEMs~\cite{belytschko1993h} reduce the mesh size $h$ locally while keeping fixed the polynomial order of approximation $p$. $p$-adaptive FEMs \cite{babuska1981p} enrich locally the polynomial space $p$ while the mesh size $h$ remains invariant. The combination of both approaches leads to the so-called $hp$-adaptive FEM~\cite{babuvska1981error}.

We encounter different $hp$-adaptive algorithms in the literature. For example, the so-called Texas three-step strategy \cite{oden1995parallel} alternates between $h$- and $p$-refinements but leads to non-optimal results. The work of Demkowicz et al.~\cite{demkowicz2002fully,demkowicz2007computing,demkowicz2008computing} produces optimal meshes by minimizing a local projection error based on a reference solution. This approach, widely utilized in diverse applications~\cite{paszynski2005verification,garcia2007two,pardo2007two,pardo2008pml,gomez2012three,paszynski2012parallel,aramberri2015hp}, requires a Projection-Based Interpolation (\revb{PBI}), which might be complex to implement. Furthermore, it calculates the reference solution over a globally refined $(\frac{h}{2}, p+1)$-grid, which is often prohibitively expensive to compute. The authors of \cite{ainsworth1998adaptive} proposed a $hp$-strategy based on the local regularity of the exact solution. Nonetheless, its wide industrial applications are unclear, a problem that this approach typically shares with some Discontinuous Galerkin (DG) methods~\cite{houston2002discontinuous,antonietti2013hp}. For a further review and comparison among some of the existing $hp$-adaptive strategies (up to 2014), we refer the reader to~\cite{mitchell2014comparison}.

The implementation of high-order $hp$-meshes is challenging. Specifically, when performing local $h$-refinements, \emph{hanging nodes} appear naturally (\revbdos{see, e.g.,}~\cite{demkowicz2007computing,solin2003higher}), \revb{and} to guarantee the continuity of the solution, \revb{we need to constrain them}. The data structures needed to deal with hanging nodes are rather complicated and have numerous technical difficulties. To avoid these inconveniences and limit the implementation complexity, Zander et al.~\cite{zander2015multi} proposed a suitable data structure that supported $hp$-discretizations while eliminating the hanging nodes by construction. This approach employs hierarchical basis functions in $h$ and $p$ in a multi-level grid, and performs uniform refinements with massive use of Dirichlet nodes to ensure continuity and enable local refinements. \revbdos{It is also possible to replace global uniform refinements by isotropic refinements over a subset of elements.}
%We perform global refinements with massive use of Dirichlet nodes to ensure continuity and enable local refinements
This \revb{vast} utilization of Dirichlet nodes avoids introducing hanging nodes and highly simplifies the existing data structures to handle $hp$-refinements. \revb{Kopp et al. extended these data structures to arbitrary dimensions~\cite{kopp2021efficient}  and space-time discretizations~\cite{kopp2021spacetime}}.

In 2020, Darrigrand et al.~\cite{darrigrand2020painless} introduced a novel automatic $hp$-adaptive mesh-refinement strategy for elliptic problems based on Zander's data structures~\cite{zander2015multi,zander2016multi,zander2017multi}. In addition to bypassing the mesh irregularities caused by hanging nodes, the main achievement was to avoid complex implementations such as local projections (\revbdos{see, e.g.,} PIB~\cite{demkowicz2002fully}) that require simultaneously maintaining multiple grids in the data structures. This easy-to-implement $hp$-strategy performs a general (user-defined) refinement step followed by a specific coarsening of the mesh. In particular, we employ quadrilateral elements and \reva{alternate} global $h$- or $p$-refinements with local and quasi-optimal $hp$-unrefinements (similarly to \cite{binev2013instance,canuto2017convergence}). For that purpose, we \revb{eliminate} the basis functions with the lowest contributions to the energy of the solution at each $hp$-unrefinement step. We notice that, although it would be possible to construct suitable a posteriori error estimators~\cite{ainsworth1997posteriori} to enhance the refinement step of the algorithm, this possibility is out of the scope of this work.

While most existing approaches execute optimal $hp$-refinement steps, the aforementioned coarsening-based strategy provides a particular advantage: it is capable of \emph{correcting} some previous \emph{mistakes} by removing undesired basis functions, possibly introduced via global refinements or during the pre-asymptotic regime. Moreover, later unrefinement iterations can also correct possible non-optimal results due to the assumed quasi-orthogonality approximation of the basis functions.

Instead of controlling the energy of the solution over the entire domain, many engineering applications aim to control errors in a specific quantity of engineering interest, and often only in certain parts of the domain. This fact motivated the development of the so-called Goal-Oriented Adaptive (GOA) strategies~\cite{becker1996weighted,rannacher1998posteriori, prudhomme1999goal,oden2001goal} as an attempt to build mesh adaptation procedures designed to approximate particular Quantities of Interest (QoI) with a reduced computational cost. GOA algorithms are standard in many engineering applications. For instance in electromagnetics \cite{pardo2006goal, pardo2007self, pardo2010multigoal, alvarez2017dimensionally}, structural problems and visco-elasticity \cite{panetier2010strict,waeytens2012guaranteed,verdugo2012computable}, fluid-structure interactions \cite{van2011goal1,van2011goal2,van2011isogeometric,wick2012goal}, or control theory \cite{hintermuller2010goal,gunther2012posteriori,hintermuller2014dual}. In particular, GOA $hp$-adaptive algorithms deliver exponential convergence rates in terms of a specific property of the solution (\revbdos{see, e.g.,}~\cite{darrigrand2015goal,holst2015convergence,darrigrand2018goal,holstpollock2016,valseth2020goal} for numerical results) even though convergence proofs are not customary \cite{rachowicz2006fully}.

%The authors of the works \cite{dorfler1996convergent,morin2000data,binev2004adaptive,stevenson2007optimality,cascon2008quasi} have demonstrated convergence and optimality for their algorithms


Darrigrand's energy-based-adaptive $hp$-strategy~\cite{darrigrand2020painless} is restricted to elliptic problems. \rev{Thus}, the main contributions of this work are to extend this method to (a) non-elliptic equations and (b) GOA approaches for elliptic and non-elliptic problems. For energy-based adaptive strategies applied to non-elliptic equations, we provide an alternative estimation of the energy contribution in terms of an inner product depending upon the bilinear form of the problem. For the GOA approach, we use the adjoint problem to construct an upper bound of the error representation expressed in terms of an inner product that depends on the bilinear form of the problem. As a result, we obtain an automatic goal-oriented $hp$-adaptive algorithm for elliptic and non-elliptic problems.

Remarkably, our algorithm is robust and straightforward to implement, and therefore, it might be of interest to industrial applications. Besides, our approach avoids the computation of reference solutions on very fine grids, as in other methods like \cite{demkowicz2002fully}. We restrict ourselves to anisotropic $p$ and isotropic $h$-refinements, and we highlight a recent work by Zander et al.~\cite{zander2022anisotropic} to extend the multi-level data structures to support anisotropic $h$-refinements. We test and analyze our algorithm in three different $2$D problems based on Poisson, Helmholtz, and convection-dominated equations, and we also provide numerical results for a $3$D Helmholtz-like problem.

We organize the remainder of this work as follows: \Cref{sec:DataStruct} describes the data structures and introduces the concept of \emph{removable} basis functions, a crucial idea in our approach. In \Cref{sec:GO-adapt}, we define the adaptive strategy and provide element-wise error indicators that guide the adaptivity for energy-norm and goal-oriented adaptivity applied to elliptic and non-elliptic problems. \Cref{sec:Numerical} illustrates the performance of our method numerically. In particular, we show the exponential convergence behavior of the approach for a wide range of $2$D and $3$D problems, and we exhibit different final $h$- and $hp$-adapted meshes. Finally, we present our conclusions in \Cref{sec:ccl}.

%\ac{AFEMs} aim to approximate accurate solutions to \ac{PDEs} with a reduced computational cost. To this end, \ac{AFEMs} perform refinements (and sometimes unrefinements, similarly to \cite{binev2013instance,canuto2017convergence}) to redistribute the error over the mesh. The \emph{a posteriori} error estimation techniques are essential ingredients to guide the mesh adaptation. There are different types of error estimation techniques: the residual error estimator (see, e.g., \cite{babuvvska1978error,babuvska1978posteriori}), the non-residual error estimator (see, e.g., \cite{zhu1990superconvergence,zienkiewicz1992superconvergentone,zienkiewicz1992superconvergenttwo}), and hierarquical basis estimators (see, e.g., \cite{bank1993posteriori}).
%
%Theoretical foundations of  \ac{FEM} with \emph{a posteriori} error estimation techniques allow us to develop automatic adaptive algorithms; see \cite{babuvska1979adaptive}. Such algorithms provide information on where refinements are required, minimizing the number of unknowns needed to achieve the error in the energy norm the user prescribes.